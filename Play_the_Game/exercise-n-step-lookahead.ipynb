{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Intro to Game AI and Reinforcement Learning](https://www.kaggle.com/learn/intro-to-game-ai-and-reinforcement-learning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/n-step-lookahead).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nIn the tutorial, you learned how to build a reasonably intelligent agent with the minimax algorithm.  In this exercise, you will check your understanding and submit your own agent to the competition.","metadata":{}},{"cell_type":"code","source":"from learntools.core import binder\nbinder.bind(globals())\nfrom learntools.game_ai.ex3 import *","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:44:23.157632Z","iopub.execute_input":"2021-07-08T11:44:23.158019Z","iopub.status.idle":"2021-07-08T11:44:23.273104Z","shell.execute_reply.started":"2021-07-08T11:44:23.157935Z","shell.execute_reply":"2021-07-08T11:44:23.272316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1) A closer look\n\nThe heuristic from the tutorial looks at all groups of four adjacent grid locations on the same row, column, or diagonal and assigns points for each occurrence of the following patterns:\n\n<center>\n<img src=\"https://i.imgur.com/3NvBEGL.png\" width=70%><br/>\n</center>\n\nIs it really necessary to use so many numbers to define the heuristic?  Consider simplifying it, as in the image below.\n\n<center>\n<img src=\"https://i.imgur.com/grViegG.png\" width=70%><br/>\n</center>\n\nHow would each heuristic score the potential moves in the example below (where, in this case, the agent looks only one step ahead)?  Which heuristic would lead to the agent selecting the better move?\n\n<center>\n<img src=\"https://i.imgur.com/LWPLy7N.png\" width=100%><br/>\n</center>","metadata":{}},{"cell_type":"code","source":"q_1.hint()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:44:23.274428Z","iopub.execute_input":"2021-07-08T11:44:23.274746Z","iopub.status.idle":"2021-07-08T11:44:23.285197Z","shell.execute_reply.started":"2021-07-08T11:44:23.274712Z","shell.execute_reply":"2021-07-08T11:44:23.284129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_1.solution()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:44:23.287509Z","iopub.execute_input":"2021-07-08T11:44:23.287949Z","iopub.status.idle":"2021-07-08T11:44:23.295884Z","shell.execute_reply.started":"2021-07-08T11:44:23.287913Z","shell.execute_reply":"2021-07-08T11:44:23.294881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2) Count the leaves\n\nIn the tutorial, we worked with a small game tree.\n\n<center>\n<img src=\"https://i.imgur.com/BrRe7Bu.png\" width=90%><br/>\n</center>\n\nThe game tree above has 8 leaf nodes that appear at the bottom of the tree.  By definition, \"leaf nodes\" in a game tree are nodes that don't have nodes below them.\n\nIn the ConnectX competition, the game trees will be much larger!  \n\nTo see this, consider a minimax agent that is trying to plan its first move, where all columns in the game board are  empty.  Say the agent builds a game tree of depth 3.  How many leaf nodes are in the game tree?  \n\nUse your answer to fill in the blank below.","metadata":{}},{"cell_type":"code","source":"# Fill in the blank\nnum_leaves = 343\n\n# Check your answer\nq_2.check()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:44:23.297772Z","iopub.execute_input":"2021-07-08T11:44:23.29816Z","iopub.status.idle":"2021-07-08T11:44:23.306266Z","shell.execute_reply.started":"2021-07-08T11:44:23.298124Z","shell.execute_reply":"2021-07-08T11:44:23.305318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\nq_2.hint()\nq_2.solution()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:44:23.307677Z","iopub.execute_input":"2021-07-08T11:44:23.308309Z","iopub.status.idle":"2021-07-08T11:44:23.319839Z","shell.execute_reply.started":"2021-07-08T11:44:23.30824Z","shell.execute_reply":"2021-07-08T11:44:23.319074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3) Which move will the agent select?\n\nIn this question, you'll check your understanding of the minimax algorithm.  Remember that with this algorithm, \n> The agent chooses moves to get a score that is as high as possible, and it assumes the opponent will counteract this by choosing moves to force the score to be as low as possible.\n\nConsider the toy example below of a game tree that the agent will use to select its next move.  \n<center>\n<img src=\"https://i.imgur.com/QlfWGM9.png\" width=80%><br/>\n</center>\n\nWhich move will the agent select?  Use your answer to set the value of the `selected_move` variable below.  Your answer should be one of `1`, `2`, or `3`.","metadata":{}},{"cell_type":"code","source":"# Fill in the blank\nselected_move = 3\n\n# Check your answer\nq_3.check()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:44:23.321002Z","iopub.execute_input":"2021-07-08T11:44:23.321521Z","iopub.status.idle":"2021-07-08T11:44:23.329264Z","shell.execute_reply.started":"2021-07-08T11:44:23.321487Z","shell.execute_reply":"2021-07-08T11:44:23.328275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\nq_3.hint()\nq_3.solution()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:44:23.330793Z","iopub.execute_input":"2021-07-08T11:44:23.331496Z","iopub.status.idle":"2021-07-08T11:44:23.343366Z","shell.execute_reply.started":"2021-07-08T11:44:23.33146Z","shell.execute_reply":"2021-07-08T11:44:23.342575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4) Examine the assumptions\n\nThe minimax agent assumes that its opponent plays optimally (with respect to the heuristic, and using a game tree of limited depth).  But this is almost never the case, in practice: it's far more likely for the agent to encounter a suboptimal (that is: worse than optimal) opponent.  \n\nSay the minimax agent encounters a suboptimal opponent. Should we expect the minimax agent to still play the game well, despite the contradiction with its assumptions?  If so, why?","metadata":{}},{"cell_type":"code","source":"q_4.hint()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:44:23.344545Z","iopub.execute_input":"2021-07-08T11:44:23.345085Z","iopub.status.idle":"2021-07-08T11:44:23.352848Z","shell.execute_reply.started":"2021-07-08T11:44:23.345035Z","shell.execute_reply":"2021-07-08T11:44:23.351886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_4.solution()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:44:23.355191Z","iopub.execute_input":"2021-07-08T11:44:23.355855Z","iopub.status.idle":"2021-07-08T11:44:23.37128Z","shell.execute_reply.started":"2021-07-08T11:44:23.355818Z","shell.execute_reply":"2021-07-08T11:44:23.370356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5) Submit to the competition\n\nNow, it's time to submit an agent to the competition!  Use the next code cell to define an agent.  (You can see an example of how to write a valid agent in **[this notebook](https://www.kaggle.com/alexisbcook/create-a-connectx-agent)**.)\n\nIf you decide to use the minimax code from the tutorial, you might like to add [**alpha-beta pruning**](https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning) to decrease the computation time (i.e., get the minimax algorithm to run much faster!).  In this case, \"alpha\" and \"beta\" to refer to two values that are maintained while the algorithm is running, that help to identify early stopping conditions.  \n\nWithout alpha-beta pruning, minimax evaluates each leaf node.  With alpha-beta pruning, minimax only evaluates nodes that could provide information that affects the agent's choice of action.  Put another way, it identifies nodes that could not possibly affect the final result and avoids evaluating them.","metadata":{}},{"cell_type":"code","source":"def my_agent(obs, config):\n    import numpy as np\n    import random\n    # Calculates score if agent drops piece in selected column\n    def score_move(grid, col, mark, config):\n        next_grid = drop_piece(grid, col, mark, config)\n        score = get_heuristic(next_grid, mark, config)\n        return score\n\n    # Helper function for score_move: gets board at next step if agent drops piece in selected column\n    def drop_piece(grid, col, mark, config):\n        next_grid = grid.copy()\n        for row in range(config.rows-1, -1, -1):\n            if next_grid[row][col] == 0:\n                break\n        next_grid[row][col] = mark\n        return next_grid\n\n    # Helper function for score_move: calculates value of heuristic for grid\n    def get_heuristic(grid, mark, config):\n        A = 10000\n        B = 100\n        C = 1\n        D = -10\n        E = -1000\n        num_twos = count_windows(grid, 2, mark, config)\n        num_threes = count_windows(grid, 3, mark, config)\n        num_fours = count_windows(grid, 4, mark, config)\n        num_twos_opp = count_windows(grid, 2, mark%2+1, config)\n        num_threes_opp = count_windows(grid, 3, mark%2+1, config)\n        score = A*num_fours + B*num_threes + C*num_twos + D*num_twos_opp + E*num_threes_opp\n        return score\n\n    # Helper function for get_heuristic: checks if window satisfies heuristic conditions\n    def check_window(window, num_discs, piece, config):\n        return (window.count(piece) == num_discs and window.count(0) == config.inarow-num_discs)\n       \n    # Helper function for get_heuristic: counts number of windows satisfying specified heuristic conditions\n    def count_windows(grid, num_discs, piece, config):\n        num_windows = 0\n        # horizontal\n        for row in range(config.rows):\n            for col in range(config.columns-(config.inarow-1)):\n                window = list(grid[row, col:col+config.inarow])\n                if check_window(window, num_discs, piece, config):\n                    num_windows += 1\n        # vertical\n        for row in range(config.rows-(config.inarow-1)):\n            for col in range(config.columns):\n                window = list(grid[row:row+config.inarow, col])\n                if check_window(window, num_discs, piece, config):\n                    num_windows += 1\n        # positive diagonal\n        for row in range(config.rows-(config.inarow-1)):\n            for col in range(config.columns-(config.inarow-1)):\n                window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n                if check_window(window, num_discs, piece, config):\n                    num_windows += 1\n        # negative diagonal\n        for row in range(config.inarow-1, config.rows):\n            for col in range(config.columns-(config.inarow-1)):\n                window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n                if check_window(window, num_discs, piece, config):\n                    num_windows += 1\n        return num_windows\n    \n    def step_2_lookahead(grid, col, mark, config):\n        next_grid = drop_piece(grid, col, mark, config)\n        score = get_heuristic(next_grid, mark, config)\n        \n        if score == 10000:\n            return score\n        \n        score2_list = []\n        for col2 in range(config.columns):\n            if next_grid[0][col2] == 0:\n                next2_grid = drop_piece(next_grid, col2, mark%2+1, config)\n                score2 = get_heuristic(next2_grid, mark%2+1, config)\n                score2_list.append(score2)\n        if score2_list != []:\n            score -= max(score2_list)\n                \n        return score\n    \n    def step_3_lookahead(grid, col, mark, config) -> int:\n        next_grid = drop_piece(grid, col, mark, config)\n        score = get_heuristic(next_grid, mark, config)\n        \n        score3_list = []\n        for col2 in range(config.columns):\n            if next_grid[0][col2] == 0:\n                score3_list.append(step_2_lookahead(next_grid, col2, mark%2+1, config))\n        if score3_list != []:\n            score -= max(score3_list)\n        \n        return score\n\n    # Get list of valid moves\n    print(config)\n    valid_moves = [c for c in range(config.columns) if obs.board[c] == 0]\n    # Convert the board to a 2D grid\n    grid = np.asarray(obs.board).reshape(config.rows, config.columns)\n    # Use the heuristic to assign a score to each possible board in the next turn\n    scores = dict(zip(valid_moves, [step_3_lookahead(grid, col, obs.mark, config) for col in valid_moves]))\n    print(scores)\n    # Get a list of columns (moves) that maximize the heuristic\n    max_cols = [key for key in scores.keys() if scores[key] == max(scores.values())]\n    # Select at random from the maximizing columns\n    return random.choice(max_cols)\n\n# Use default Connect Four setup\nlcl_obs = {'board': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 2, 1, 2, 0, 0],\n           'mark': 1}\nconfig = {'rows': 6, 'columns': 7, 'inarow': 4}\n\nclass AttrDict(dict):\n    def __init__(self, *args, **kwargs):\n        super(AttrDict, self).__init__(*args, **kwargs)\n        self.__dict__ = self\nlcl_obs = AttrDict(lcl_obs)\nconfig = AttrDict(config)\n# Agent 1 goes first (roughly) half the time          \nlcl_col = my_agent(lcl_obs, config)\nprint(lcl_col)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T05:05:40.653983Z","iopub.execute_input":"2021-07-09T05:05:40.654393Z","iopub.status.idle":"2021-07-09T05:05:42.539651Z","shell.execute_reply.started":"2021-07-09T05:05:40.654362Z","shell.execute_reply":"2021-07-09T05:05:42.538631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def my_agent2(obs, config):\n    import numpy as np\n    import random\n    # Calculates score if agent drops piece in selected column\n    def score_move(grid, col, mark, config):\n        next_grid = drop_piece(grid, col, mark, config)\n        score = get_heuristic(next_grid, mark, config)\n        return score\n\n    # Helper function for score_move: gets board at next step if agent drops piece in selected column\n    def drop_piece(grid, col, mark, config):\n        next_grid = grid.copy()\n        for row in range(config.rows-1, -1, -1):\n            if next_grid[row][col] == 0:\n                break\n        next_grid[row][col] = mark\n        return next_grid\n\n    # Helper function for score_move: calculates value of heuristic for grid\n    def get_heuristic(grid, mark, config):\n        A = 10000\n        B = 100\n        C = 1\n        D = -10\n        E = -1000\n        num_twos = count_windows(grid, 2, mark, config)\n        num_threes = count_windows(grid, 3, mark, config)\n        num_fours = count_windows(grid, 4, mark, config)\n        num_twos_opp = count_windows(grid, 2, mark%2+1, config)\n        num_threes_opp = count_windows(grid, 3, mark%2+1, config)\n        score = A*num_fours + B*num_threes + C*num_twos + D*num_twos_opp + E*num_threes_opp\n        return score\n\n    # Helper function for get_heuristic: checks if window satisfies heuristic conditions\n    def check_window(window, num_discs, piece, config):\n        return (window.count(piece) == num_discs and window.count(0) == config.inarow-num_discs)\n       \n    # Helper function for get_heuristic: counts number of windows satisfying specified heuristic conditions\n    def count_windows(grid, num_discs, piece, config):\n        num_windows = 0\n        # horizontal\n        for row in range(config.rows):\n            for col in range(config.columns-(config.inarow-1)):\n                window = list(grid[row, col:col+config.inarow])\n                if check_window(window, num_discs, piece, config):\n                    num_windows += 1\n        # vertical\n        for row in range(config.rows-(config.inarow-1)):\n            for col in range(config.columns):\n                window = list(grid[row:row+config.inarow, col])\n                if check_window(window, num_discs, piece, config):\n                    num_windows += 1\n        # positive diagonal\n        for row in range(config.rows-(config.inarow-1)):\n            for col in range(config.columns-(config.inarow-1)):\n                window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n                if check_window(window, num_discs, piece, config):\n                    num_windows += 1\n        # negative diagonal\n        for row in range(config.inarow-1, config.rows):\n            for col in range(config.columns-(config.inarow-1)):\n                window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n                if check_window(window, num_discs, piece, config):\n                    num_windows += 1\n        return num_windows\n    \n    def step_2_lookahead(grid, col, mark, config):\n        next_grid = drop_piece(grid, col, mark, config)\n        score = get_heuristic(next_grid, mark, config)\n        if score == 10000:\n            return score\n        \n        score2_list = []\n        for col2 in range(config.columns):\n            if next_grid[0][col2] == 0:\n                next2_grid = drop_piece(next_grid, col2, mark%2+1, config)\n                score2 = get_heuristic(next2_grid, mark%2+1, config)\n                score2_list.append(score2)\n        if score2_list != []:\n            score -= max(score2_list)\n \n        return score\n\n    # Get list of valid moves\n    print(config)\n    valid_moves = [c for c in range(config.columns) if obs.board[c] == 0]\n    # Convert the board to a 2D grid\n    grid = np.asarray(obs.board).reshape(config.rows, config.columns)\n    # Use the heuristic to assign a score to each possible board in the next turn\n    scores = dict(zip(valid_moves, [step_2_lookahead(grid, col, obs.mark, config) for col in valid_moves]))\n    # Get a list of columns (moves) that maximize the heuristic\n    print(scores)\n    max_cols = [key for key in scores.keys() if scores[key] == max(scores.values())]\n    # Select at random from the maximizing columns\n    return random.choice(max_cols)\n\n# Use default Connect Four setup\nlcl_obs = {'board': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 2, 1, 2, 0, 0],\n          'mark': 1}\nconfig = {'rows': 6, 'columns': 7, 'inarow': 4}\n\nclass AttrDict(dict):\n    def __init__(self, *args, **kwargs):\n        super(AttrDict, self).__init__(*args, **kwargs)\n        self.__dict__ = self\nlcl_obs = AttrDict(lcl_obs)\nconfig = AttrDict(config)\n# Agent 1 goes first (roughly) half the time          \nlcl_col = my_agent2(lcl_obs, config)\nprint(lcl_col)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T04:31:05.172249Z","iopub.execute_input":"2021-07-09T04:31:05.173355Z","iopub.status.idle":"2021-07-09T04:31:05.533198Z","shell.execute_reply.started":"2021-07-09T04:31:05.173286Z","shell.execute_reply":"2021-07-09T04:31:05.530805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run this code cell to get credit for creating an agent\nq_5.check()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:44:23.475373Z","iopub.execute_input":"2021-07-08T11:44:23.475717Z","iopub.status.idle":"2021-07-08T11:44:23.489014Z","shell.execute_reply.started":"2021-07-08T11:44:23.475685Z","shell.execute_reply":"2021-07-08T11:44:23.487954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_environments import make, evaluate\n\n# Create the game environment\nenv = make(\"connectx\")\n\n# Two random agents play one game round\nenv.run([my_agent, my_agent2])\n\n# Show the game\nenv.render(mode=\"ipython\")","metadata":{"execution":{"iopub.status.busy":"2021-07-09T05:06:11.236634Z","iopub.execute_input":"2021-07-09T05:06:11.237126Z","iopub.status.idle":"2021-07-09T05:06:35.970313Z","shell.execute_reply.started":"2021-07-09T05:06:11.237083Z","shell.execute_reply":"2021-07-09T05:06:35.967355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ndef get_win_percentages(agent1, agent2, n_rounds=10):\n    # Use default Connect Four setup\n    config = {'rows': 6, 'columns': 7, 'inarow': 4}\n    # Agent 1 goes first (roughly) half the time          \n    outcomes = evaluate(\"connectx\", [agent1, agent2], config, [], n_rounds//2)\n    # Agent 2 goes first (roughly) half the time      \n    outcomes += [[b,a] for [a,b] in evaluate(\"connectx\", [agent2, agent1], config, [], n_rounds-n_rounds//2)]\n    print(\"Agent 1 Win Percentage:\", np.round(outcomes.count([1,-1])/len(outcomes), 2))\n    print(\"Agent 2 Win Percentage:\", np.round(outcomes.count([-1,1])/len(outcomes), 2))\n    print(\"Number of Invalid Plays by Agent 1:\", outcomes.count([None, 0]))\n    print(\"Number of Invalid Plays by Agent 2:\", outcomes.count([0, None]))\n    \nget_win_percentages(agent1=my_agent, agent2=my_agent2)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T05:06:55.979169Z","iopub.execute_input":"2021-07-09T05:06:55.979821Z","iopub.status.idle":"2021-07-09T05:10:45.358584Z","shell.execute_reply.started":"2021-07-09T05:06:55.979759Z","shell.execute_reply":"2021-07-09T05:10:45.357175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import inspect\nimport os\n\ndef write_agent_to_file(function, file):\n    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n        f.write(inspect.getsource(function))\n        print(function, \"written to\", file)\n\nwrite_agent_to_file(my_agent, \"submission.py\")","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:44:48.035356Z","iopub.status.idle":"2021-07-08T11:44:48.036098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, follow these steps to submit your agent to the competition:\n1. Begin by clicking on the blue **Save Version** button in the top right corner of the window.  This will generate a pop-up window.  \n2. Ensure that the **Save and Run All** option is selected, and then click on the blue **Save** button.\n3. This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **Save Version** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n4. Click on the **Output** tab on the right of the screen.  Then, click on the file you would like to submit, and click on the blue **Submit** button to submit your results to the leaderboard.\n\nYou have now successfully submitted to the competition!\n\nIf you want to keep working to improve your performance, select the blue **Edit** button in the top right of the screen. Then you can change your code and repeat the process. There's a lot of room to improve, and you will climb up the leaderboard as you work.\n\n\nGo to **\"My Submissions\"** to view your score and episodes being played.\n\n# Keep going\n\nMove on to learn how to **[use deep reinforcement learning](https://www.kaggle.com/alexisbcook/deep-reinforcement-learning)** to develop an agent without a heuristic!","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/161477) to chat with other Learners.*","metadata":{}}]}